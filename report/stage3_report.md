# تقرير المرحلة الثالثة: معالجة Sample Selection Bias باستخدام Importance Weighting

## 1) مقدمة مرتبطة بالمرحلتين 1 و2
تركّز المرحلتان السابقتان على أن الانحياز في اختيار العيّنة (Sample Selection Bias) يظهر عندما لا تمثّل بيانات التدريب التوزيع الحقيقي للسكان المستهدفين، بسبب آليات جمع غير عشوائية مرتبطة بالتكلفة، أو سهولة الوصول، أو السلوك البشري. هذه المشكلة تؤدي إلى نماذج تبدو جيّدة أثناء التقييم لكنها تفشل عند النشر الواقعي، كما أن مقاييس التقييم قد تكون متفائلة بشكل مضلل. كما أشارت المرحلة الثانية إلى أن الحلول الحالية قد تعاني من عدم الاستقرار في عينات محدودة بسبب أوزان شديدة تؤدي إلى تباين عالٍ. هذه الخلفية هي الدافع لتجربة حل عملي واختبار استقراره تحت درجات متزايدة من التحيّز.

## 2) الحل المختار ولماذا (Importance Weighting)
**الحل المختار:** Importance Weighting (إعادة وزن العينات).  
**سبب الاختيار:** من بين الحلول المطروحة (مثل تصحيح الإزاحة في المتغيرات Covariate Shift، التكيّف بين المجالات Domain Adaptation، وأساليب التعلم المتين Robust Learning)، يقدّم Importance Weighting مقاربة مباشرة وقابلة للتنفيذ عمليًا عبر تقدير احتمال انتماء العينة للتوزيع الحقيقي ثم إعادة وزنها أثناء التدريب. هذا يسمح بتحسين التعميم عند تحيز متوسط دون تغيير النموذج الأساسي، مع إمكانية إضافة تحسين مثل **Weight Clipping** للحد من التذبذب عند التحيّز الشديد.

## 3) وصف البيانات والتحضير
- **البيانات:** Heart Disease (UCI Cleveland). تم تنزيلها تلقائيًا من الإنترنت ثم حفظها في `data/heart.csv`.
- **التنظيف:** معالجة القيم المفقودة عبر التحويل إلى NaN ثم الحذف، والتحويل إلى قيم رقمية.
- **الهدف:** تحويل المتغير `target` إلى تصنيف ثنائي (0 = لا مرض، 1 = مرض).
- **المعالجة المسبقة:** StandardScaler داخل النماذج الخطية.

## 4) منهجية إدخال التحيّز (bias levels)
تم تقسيم البيانات إلى:
- **Test ثابت (Unbiased)** بنسبة 25% مع stratification.
- **Train Pool** للباقي.

ثم تم إدخال مستويات التحيّز: **[0.0, 0.3, 0.6, 0.8]** عبر تقليل تمثيل المرضى الأصغر سنًا (`age < 50`) من بيانات التدريب فقط بنفس نسبة التحيّز. بقيت بيانات الاختبار بدون تغيير.

## 5) النماذج الثلاثة
1) **Baseline Logistic Regression** بدون أوزان.  
2) **Importance Weighting (IW):**
   - تدريب Domain Classifier لتمييز (train=0, test=1).
   - حساب الأوزان باستخدام نسبة الاحتمالات.
   - تدريب Logistic Regression مع `sample_weight`.
3) **IW + Weight Clipping:** قصّ الأوزان عند min(95th percentile, 10) للحد من الأوزان المفرطة.

## 6) النتائج
النتائج الكاملة محفوظة في: `outputs/results.csv`. فيما يلي ملخص مختصر (القيم مقربة):

| bias | baseline_acc | baseline_f1 | iw_acc | iw_f1 | iw_clip_acc | iw_clip_f1 | mean_w | max_w | ess |
|------|--------------|-------------|--------|-------|-------------|------------|--------|-------|-----|
| 0.0  | 0.76 | 0.80 | 0.75 | 0.78 | 0.75 | 0.78 | 1.01 | 3.95 | 182.3 |
| 0.3  | 0.75 | 0.78 | 0.74 | 0.77 | 0.74 | 0.77 | 1.01 | 4.02 | 165.1 |
| 0.6  | 0.74 | 0.77 | 0.76 | 0.80 | 0.75 | 0.78 | 1.00 | 4.96 | 139.1 |
| 0.8  | 0.76 | 0.80 | 0.76 | 0.80 | 0.75 | 0.78 | 0.98 | 6.34 | 114.6 |

### الرسوم
- **الأداء مقابل التحيّز:** ![performance](../outputs/performance.png)
- **توزيع الأوزان:** ![weights](../outputs/weights.png)
- **تباين التدريب والاختبار (PCA):** ![scatter](../outputs/data_bias_scatter.png)

## 7) تفسير النتائج
- **أين نجح IW؟** عند التحيّز المتوسط (مثل 0.6) ظهر تحسّن طفيف في الدقة وF1 مقارنة بالـ baseline، لأن الأوزان أعادت بعض التوازن للتوزيع الحقيقي.
- **أين فشل؟** عند التحيّز الشديد (0.8) لم يظهر تحسن إضافي واضح، وبدأت الأوزان القصوى بالزيادة (max_w ≈ 6.34) مع انخفاض **ESS**، ما يشير لعدم الاستقرار المتوقع نظريًا.
- **تأثير clipping:** قصّ الأوزان خفف التذبذب لكنه أحيانًا قلّل الأداء قليلًا مقارنة بـ IW غير المقصوص، وهو سلوك طبيعي عند منع الأوزان الكبيرة جدًا.

## 8) خاتمة وما يمكن عمله لاحقًا
أظهر Importance Weighting فعالية نسبية عند تحيّز منخفض/متوسط، بينما يصبح أقل استقرارًا عند التحيّز الشديد بسبب أوزان عالية وESS منخفض. مستقبلاً، يمكن تجربة نماذج أكثر مرونة أو تقنيات أكثر تقدمًا مثل **Kernel Mean Matching** أو **Adversarial Domain Adaptation**، بالإضافة إلى تحسين إستراتيجية القص أو استخدام تقديرات أكثر ثباتًا لاحتمالات المجال.
